## 公告：

# 第一章 初探大数据

> 完整版：链接: https://pan.baidu.com/s/1c1MECDE 密码: xki7 
>
> 纯净版：链接：链接: https://pan.baidu.com/s/1jHFGRWU 密码: m83e 
>
> 单独的data: 链接: https://pan.baidu.com/s/1nvDjdqT 密码: ufhe 
>
> 路径和密码说明： 链接：http://pan.baidu.com/s/1qXAKeeC 密码：xzik 
>
> 慕课网原始日志：链接: https://pan.baidu.com/s/1nvmeKKL 密码: 4rfd 
>
> 手记《基于CentOS6.4环境编译Spark-2.1.0源码》：http://www.imooc.com/article/18419 





课程整套CDH相关的软件下载地址：http://archive.cloudera.com/cdh5/cdh/5/
cdh-5.7.0  [hadoop-2.6.0-cdh5.7.0.tar.gz](http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.0.tar.gz) 
生产或者测试环境选择对应CDH版本时，一定要采用尾号是一样的版本



http://hadoop.apache.org/
对于Apache的顶级项目来说，projectname.apache.org
Hadoop: hadoop.apache.org
Hive: hive.apache.org
Spark: spark.apache.org
HBase: hbase.apache.org

为什么很多公司选择Hadoop作为大数据平台的解决方案？
1）源码开源
2）社区活跃、参与者很多  Spark
3）涉及到分布式存储和计算的方方面面： 
	Flume进行数据采集
	Spark/MR/Hive等进行数据处理
	HDFS/HBase进行数据存储
4) 已得到企业界的验证



## HDFS架构

1 Master(NameNode/NN)  带 N个Slaves(DataNode/DN)
HDFS/YARN/HBase

1个文件会被拆分成多个Block
blocksize：128M
130M ==> 2个Block： 128M 和 2M

NN：
1）负责客户端请求的响应
2）负责元数据（文件的名称、副本系数、Block存放的DN）的管理

DN：
1）存储用户的文件对应的数据块(Block)
2）要定期向NN发送心跳信息，汇报本身及其所有的block信息，健康状况

A typical deployment has a dedicated machine that runs only the NameNode software. 
Each of the other machines in the cluster runs one instance of the DataNode software.
The architecture does not preclude running multiple DataNodes on the same machine 
but in a real deployment that is rarely the case.

NameNode + N个DataNode
建议：NN和DN是部署在不同的节点上

replication factor：副本系数、副本因子

All blocks in a file except the last block are the same size



本课程软件存放目录
hadoop/hadoop
/home/hadoop
	software: 存放的是安装的软件包
	app : 存放的是所有软件的安装目录
	data: 存放的是课程中所有使用的测试数据目录
	source: 存放的是软件源码目录，spark

## Hadoop环境搭建

1) 下载Hadoop
	http://archive.cloudera.com/cdh5/cdh/5/
	2.6.0-cdh5.7.0

```
wget http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.0.tar.gz
```

2）安装jdk
	下载
	解压到app目录：tar -zxvf jdk-7u51-linux-x64.tar.gz -C ~/app/
	验证安装是否成功：~/app/jdk1.7.0_51/bin      ./java -version
	建议把bin目录配置到系统环境变量(~/.bash_profile)中

```shell		
export JAVA_HOME=/home/hadoop/app/jdk1.7.0_51
export PATH=JAVA_HOME/bin:PATH
```

3）机器参数设置
	hostname: hadoop001
	

```
修改机器名: /etc/sysconfig/network
	NETWORKING=yes
	HOSTNAME=hadoop001

设置ip和hostname的映射关系: /etc/hosts
	192.168.199.200 hadoop001
	127.0.0.1 localhost

ssh免密码登陆(本步骤可以省略，但是后面你重启hadoop进程时是需要手工输入密码才行)
	ssh-keygen -t rsa
	cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys
```

4）Hadoop配置文件修改: ~/app/hadoop-2.6.0-cdh5.7.0/etc/hadoop
	hadoop-env.sh
		export JAVA_HOME=/home/hadoop/app/jdk1.7.0_51

```shell
core-site.xml
	<property>
    	<name>fs.defaultFS</name>
    	<value>hdfs://hadoop001:8020</value>
	</property>	

	<property>
    	<name>hadoop.tmp.dir</name>
    	<value>/home/hadoop/app/tmp</value>
	</property>	

hdfs-site.xml
	<property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
```

5）格式化HDFS
	注意：这一步操作，只是在第一次时执行，每次如果都格式化的话，那么HDFS上的数据就会被清空
	bin/hdfs namenode -format

6）启动HDFS
	sbin/start-dfs.sh

```
验证是否启动成功:
	jps
		DataNode
		SecondaryNameNode
		NameNode

	浏览器
		http://hadoop001:50070/
```

7）停止HDFS
	sbin/stop-dfs.sh

## 分布式文件系统HFDS

优点：

> 高容错
>
> 适合批处理
>
> 适合大数据处理
>
> 可构建在廉价机器上

缺点：

> 低延迟的数据访问
>
> 不适合小文件存储

## 分布式计算框架MapReduce

什么是MapReduce

- 源于Google的MapReduce论文
- 发表于2004年12月，Hadoop MapReduce是Google MapReduce的克隆版

MapReduce特点

- 易于编程
- 良好的扩展性
- 高容错性
- 海量数据的离线处理

MapReduce不擅长的场景

- 实时计算
- 流式计算
- DAG计算（存在依赖关系的计算）

MapReduce编程模型

- input
- map&reduce
- output



## YARN架构

资源调度框架YARN

YARN产生背景

MapReduce1.x存在的问题

![MapReduce1.x体系结构](https://upload-images.jianshu.io/upload_images/5959612-0ad77c6889b899c3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

一个JobTracker+多个TaskTracker，通过心跳机制维持联系

JobTracker：资源管理和任务调度

TaskTracker：任务执行

JobTracker功能比较多，存在单点故障；

资源利用率不高并且运维成本高



由于上面的两个问题催生了YARN的诞生，不同的集器资源可以共享，提高资源利用率

![YARN体系结构](https://upload-images.jianshu.io/upload_images/5959612-6ccac7a90757175b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



### YARN组件介绍

![YARN架构](https://upload-images.jianshu.io/upload_images/5959612-5c472446fe31fda6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**1 RM(ResourceManager) + N NM(NodeManager)**

**ResourceManager的职责：** 一个集群active状态的RM只有一个，负责整个集群的资源管理和调度
1）处理客户端的请求(启动/杀死)
2）启动/监控ApplicationMaster(一个作业对应一个AM)
3）监控NM
4）系统的资源分配和调度

**NodeManager：**整个集群中有N个，负责单个节点的资源管理和使用以及task的运行情况
1）定期向RM汇报本节点的资源使用请求和各个Container的运行状态
2）接收并处理RM的container启停的各种命令
3）单个节点的资源管理和任务管理

**ApplicationMaster：**每个应用/作业对应一个，负责应用程序的管理
1）数据切分
2）为应用程序向RM申请资源(container)，并分配给内部任务
3）与NM通信以启停task， task是运行在container中的
4）task的监控和容错

**Container：**
对任务运行情况的描述：cpu、memory、环境变量



### YARN执行流程

1）用户向YARN提交作业
2）RM为该作业分配第一个container(用来启动ApplicationMaster)
3）RM会与对应的NM通信，要求NM在这个container上启动应用程序的AM
4）AM首先向RM注册，然后AM将为各个任务申请资源，并监控运行情况
5）AM采用轮训的方式通过RPC协议向RM申请和领取资源
6）AM申请到资源以后，便和相应的NM通信，要求NM启动任务
7）NM启动我们作业对应的task



### YARN环境搭建

**mapred-site.xml**

```shell
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
```

**yarn-site.xml**

```shell
<property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
</property>
```



**启动yarn：**sbin/start-yarn.sh

验证是否启动成功

```shell
jps
	ResourceManager
	NodeManager
web: http://hadoop001:8088
```

停止yarn： sbin/stop-yarn.sh

提交mr作业到yarn上运行： wc

/home/hadoop/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar

hadoop jar /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar wordcount /input/wc/hello.txt /output/wc/

当我们再次执行该作业时，会报错：
FileAlreadyExistsException: 
Output directory hdfs://hadoop001:8020/output/wc already exists



## Hive介绍

### **Hive产生背景**

- MapReduce编程的不便性
- HDFS上的文件缺少Schema(表名，名称，ID等，为数据库对象的集合)

### **Hive是什么**

- 由Facebook开源，最初用于解决海量结构化的日志数据统计问题
- 构建在Hadoop之上的数据仓库
- Hive定义了一种类SQL查询语言：HQL（类似SQL但不完全相同）
- 通常用于进行离线数据处理（早期采用MapReduce）
- 底层支持多种不同的执行引擎（现在可以直接把Hive跑在Spark上面）

**Hive底层的执行引擎有：MapReduce、Tez、Spark**

> Hive on MapReduce
>
> Hive on Tez
>
> Hive on Spark

- 支持多种不同的压缩格式、存储格式以及自定义函数

> 压缩：GZIP、LZO、Snappy、BZIP2..

> 存储：TextFile、SequenceFile、RCFile、ORC、Parquet

> UDF：自定义函数

备注：它是一个针对Hadoop数据处理应用程序的新分布式执行框架。 Tez是Apache最新的支持DAG作业的开源计算框架，它可以将多个有依赖的作业转换为一个作业从而大幅提升DAG作业的性能。 

### 为什么要使用Hive

- 简单容易上手（提供了类似SQL查询语言HQL）
- 为超大数据集设计的计算/存储扩展能力（MR计算，HDFS存储）
- 统一的元数据管理（可与Presto/Impala/SparkSQL等共享数据）



### Hive体系架构

**客户端：**可以通过shell脚本的方式访问，或者通过Thrift协议，按照平时编写JDBC的方式完成对Hive的数据操作

**Driver：**输入了sql字符串，对sql字符串进行解析，转化程抽象语法树，再转化程逻辑计划，然后使用优化工具对逻辑计划进行优化，最终生成物理计划（序列化反序列化，UDF函数），交给Execution执行引擎，提交到MapReduce上执行（输入和输出可以是本地的也可以是HDFS/Hbase）

Metastore进行元数据管理：Derby（内置 ）、Mysql

![Hive体系架构](https://upload-images.jianshu.io/upload_images/5959612-73a17253df73e8a1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



### Hive部署架构--测试环境

Derby只接受一个Hive的会话访问

![Hive部署架构--测试环境](https://upload-images.jianshu.io/upload_images/5959612-4e30c677093f70c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



### Hive部署架构--生产环境

Hive跑在Hadoop之上的，Mysql进行主备（定时同步操作）

![image.png](https://upload-images.jianshu.io/upload_images/5959612-446971a739c56057.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



### Hive环境搭建

1）Hive下载：http://archive.cloudera.com/cdh5/cdh/5/
	wget http://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.7.0.tar.gz

2）解压
	tar -zxvf hive-1.1.0-cdh5.7.0.tar.gz -C ~/app/

3）配置
	系统环境变量(~/.bahs_profile)

```shell
export HIVE_HOME=/home/hadoop/app/hive-1.1.0-cdh5.7.0
export PATH=HIVE_HOME/bin:PATH
```

实现安装一个mysql， yum install xxx

**hive-site.xml**

```shell
<property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://localhost:3306/sparksql?createDatabaseIfNotExist=true</value>
</property>

<property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
</property>

<property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>root</value>
</property>

<property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>root</value>
</property>
```

4）拷贝mysql驱动到$HIVE_HOME/lib/

5）启动hive: $HIVE_HOME/bin/hive



### Hive基本使用

- 创建表

CREATE  TABLE table_name 
  [(col_name data_type [COMMENT col_comment])]

> create table hive_wordcount(context string);

- 加载数据到hive表

LOAD DATA LOCAL INPATH 'filepath' INTO TABLE tablename 

> load data local inpath '/home/hadoop/data/hello.txt' into table hive_wordcount;

> select word, count(1) from hive_wordcount lateral view explode(split(context,'\t')) wc as word group by word;

lateral view explode(): 是把每行记录按照指定分隔符进行拆解

hive sql提交执行以后会生成mr作业，并在yarn上运行

- 案例

员工表

create table emp(
empno int,
ename string,
job string,
mgr int,
hiredate string,
sal double,
comm double,
deptno int
) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';

部门表

create table dept(
deptno int,
dname string,
location string
) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';

load data local inpath '/home/hadoop/data/emp.txt' into table emp;
load data local inpath '/home/hadoop/data/dept.txt' into table dept;

求每个部门的人数
select deptno, count(1) from emp group by deptno;

