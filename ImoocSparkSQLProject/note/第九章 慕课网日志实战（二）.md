# 第九章 慕课网日志实战（二）

[TOC]

## 19 功能实现之数据可视化展示概述

数据可视化展示概述

- 什么时数据可视化
- 使用SQL API完成统计分析为什么要可视化
- 常见的可视化框架

数据可视化：一副图片最伟大的价值莫过于它能够使得我们实际看到的比我们期望看到的内容更加丰富

常见的可视化框架
1）echarts
2）highcharts
3）D3.js
4）HUE 
5）Zeppelin



## 20 Echarts饼状静态数据展示

Echarts的基本使用

- 饼图静态数据展示

官网：http://echarts.baidu.com



## 21 ECharts饼状动态展示之一查询MySQL中的数据

Echarts的基本使用

- 饼图动态数据展示

```
操作MySQL的工具类：MySQLUtils
实体类javaBean:  VideoAccessTopN
面向接口编程：VideoAccessTopNDAO.query(day)
```



## 22 Echarts饼图动态展示之二前端开发

在servlet中写doGet方法，调用dao获取数据然后以json的格式返回

在web.xml中注册servlet



## 23 使用Zeppelin进行统计结果的展示

开源可视化框架Zeppelin的使用

```shell
错误
java.sql.SQLException: Access denied for user 'root'@'hadoop001' (using password: YES)

$ grant all privileges on *.* to root@hadoop001 identified by 'root';
```

```shell
%jdbc

select cms_id, times from day_video_access_topn_stat where day='20170511' order by times desc limit 5
```

![image.png](https://upload-images.jianshu.io/upload_images/5959612-2189f76d606dfe21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)





## 24 Spark on Yarn基础

概述

- Spark支持可插拔的集群管理模式
- 对于YARN而言，Spark Application仅仅是一个客户端而已

在Spark中，支持4种运行模式：
1）Local：开发时使用
2）Standalone： 是Spark自带的，如果一个集群是Standalone的话，那么就需要在多台机器上同时部署Spark环境
3）YARN：建议大家在生产上使用该模式，统一使用YARN进行整个集群作业(MR、Spark)的资源调度
4）Mesos

不管使用什么模式，Spark应用程序的代码是一模一样的，只需要在提交的时候通过--master参数来指定我们的运行模式即可

![image.png](https://upload-images.jianshu.io/upload_images/5959612-bb6b7f2144cf7a5c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**Spark on YARN之client模式**

Client
	Driver运行在Client端(提交Spark作业的机器)
	Client会和请求到的Container进行通信来完成作业的调度和执行，Client是不能退出的
	日志信息会在控制台输出：便于我们测试

![Spark on YARN之client模式](https://upload-images.jianshu.io/upload_images/5959612-f5a2157987c4670a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



**Spark on YARN之cluster模式**

Cluster
	Driver运行在ApplicationMaster中
	Client只要提交完作业之后就可以关掉，因为作业已经在YARN上运行了
	日志是在终端看不到的，因为日志是在Driver上，只能通过yarn logs -applicationId application_id

![Spark on YARN之cluster模式](https://upload-images.jianshu.io/upload_images/5959612-992fd60739d6c384.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



Spark on Yarn之两种模式对比

- Driver的运行位置（client端；ApplicationMaster端）
- ApplicationMaster的职责（到Yarn Resource Manager申请资源；申请资源和作业调度 ）
- 运行输出日志的位置（控制台；在Driver上）



```shell
./bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master yarn \
--executor-memory 1G \
--num-executors 1 \
/home/hadoop/app/spark-2.1.0-bin-2.6.0-cdh5.7.0/examples/jars/spark-examples_2.11-2.1.0.jar \
4

spark-submit --class org.apache.spark.examples.SparkPi --master yarn --executor-memory 1G --num-executors 1 /home/hadoop/app/spark-2.1.0-bin-2.6.0-cdh5.7.0/examples/jars/spark-examples_2.11-2.1.0.jar 4
```

**此处的yarn就是我们的yarn client模式**
**如果是yarn cluster模式的话，yarn-cluster**

```shell
Exception in thread "main" java.lang.Exception: When running with master 'yarn' either HADOOP_CONF_DIR or YARN_CONF_DIR must be set in the environment.
```

如果想运行在YARN之上，那么就必须要设置HADOOP_CONF_DIR或者是YARN_CONF_DIR

1） export HADOOP_CONF_DIR=/home/hadoop/app/hadoop-2.6.0-cdh5.7.0/etc/hadoop
2)    $SPARK_HOME/conf/spark-env.sh

**Cluster模式示例**

```shell
./bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master yarn-cluster \
--executor-memory 1G \
--num-executors 1 \
/home/hadoop/app/spark-2.1.0-bin-2.6.0-cdh5.7.0/examples/jars/spark-examples_2.11-2.1.0.jar \
4

spark-submit --class org.apache.spark.examples.SparkPi --master yarn-cluster --executor-memory 1G --num-executors 1 /home/hadoop/app/spark-2.1.0-bin-2.6.0-cdh5.7.0/examples/jars/spark-examples_2.11-2.1.0.jar 4

//正常启动后查看日志
$ yarn logs -applicationId application_1528340270847_0002
```



```shell
//错误
2018-06-06 18:52:01,562 WARN org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Directory /tmp/hadoop-hadoop/nm-local-dir error, used space above threshold of 90.0%, removing from list of valid directories
2018-06-06 18:52:01,562 WARN org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Directory /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/userlogs error, used space above threshold of 90.0%, removing from list of valid directories

命令显示yarn各节点状态： 
$ yarn node -list -all  
查看磁盘的信息：
$ df -h
```







## 25 数据清洗作业运行在YARN上

将我们的项目运行在YARN之上

- 将我们的项目通过maven进行打包
- 通过spark-submit方式提交



打包时要注意，pom.xml中需要添加如下plugin

```xml
<plugin>
    <artifactId>maven-assembly-plugin</artifactId>
    <configuration>
        <archive>
            <manifest>
                <mainClass></mainClass>
            </manifest>
        </archive>
        <descriptorRefs>
            <descriptorRef>jar-with-dependencies</descriptorRef>
        </descriptorRefs>
    </configuration>
</plugin>
```

编译打包

```shell
mvn assembly:assembly
```

上传jar包；在hdfs，上传慕课日志文件；上传场景文件

```shell
./bin/spark-submit \
--class com.imooc.log.SparkStatCleanJobYARN \
--name SparkStatCleanJobYARN \
--master yarn \
--executor-memory 1G \
--num-executors 1 \
--files /home/hadoop/lib/ipDatabase.csv,/home/hadoop/lib/ipRegion.xlsx \
/home/hadoop/lib/sql-1.0-jar-with-dependencies.jar \
hdfs://hadoop001:8020/imooc/input/* hdfs://hadoop001:8020/imooc/clean


###########
spark-submit --class com.imooc.log.SparkStatCleanJobYARN --name SparkStatCleanJobYARN --master yarn --executor-memory 1G --num-executors 1 --files /home/hadoop/lib/mylib/ipDatabase.csv,/home/hadoop/lib/mylib/ipRegion.xlsx /home/hadoop/lib/sql-1.0-jar-with-dependencies.jar hdfs://hadoop001:8020/imooc/input/* hdfs://hadoop001:8020/imooc/clean
```

注意：--files在spark中的使用

查询执行的作业

```shell
spark.read.format("parquet").load("/imooc/clean/day=20170511/part-00000-804dd5dc-77d0-4ee9-982e-aa5b932ea519.snappy.parquet").show(false)
```



## 9-26 统计作业运行在YARN上

创建三个表：

```shell
create table day_video_access_topn_stat (
day varchar(8) not null,
cms_id bigint(10) not null, 
times bigint(10) not null,  
primary key (day, cms_id)
);

create table day_video_city_access_topn_stat (
day varchar(8) not null,
cms_id bigint(10) not null,
city varchar(20) not null,
times bigint(10) not null,
times_rank int not null,
primary key (day, cms_id, city)
);

create table day_video_traffics_topn_stat (
day varchar(8) not null,
cms_id bigint(10) not null,
traffics bigint(20) not null,
primary key (day, cms_id)
);
```



```shell
./bin/spark-submit \
--class com.imooc.log.TopNStatJobYARN \
--name TopNStatJobYARN \
--master yarn \
--executor-memory 1G \
--num-executors 1 \
/home/hadoop/lib/sql-1.0-jar-with-dependencies.jar \
hdfs://hadoop001:8020/imooc/clean 20170511 
```



## 27 性能优化之存储格式的选择

### 1）存储格式

- 行式存储
- 列式存储

行存储的写入式一次完成；

列存储需要把一行数据拆分成单列保存，写入次数明显比行存储多；

**所以行存储再写入上比列存储优势大**



**但是再读取性能上，列存储优势明显，**尤其是再大数据中的数据存储

存储格式的选择：http://www.infoq.com/cn/articles/bigdata-store-choose/



## 28 性能调优之压缩格式的选择

### 1）压缩格式的选择

压缩速度

压缩文件的分割性（并行性）



优点：节省数据占用的磁盘空间、加快数据再磁盘和网络中的传输速度，从而提高系统的处理速度



压缩格式的选择：https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-compression-analysis/



## 29 性能优化之代码优化

代码优化：

- 选用高性能的算子
- 复用已有的数据



## 30 参数优化

- 并行度：spark.sql.shuffle.partitions
- 分区字段类型推测：spark.sql.sources.partitionColumnTypeInference.enabled



调整并行度

```shell
./bin/spark-submit \
--class com.imooc.log.TopNStatJobYARN \
--name TopNStatJobYARN \
--master yarn \
--executor-memory 1G \
--num-executors 1 \
--conf spark.sql.shuffle.partitions=100 \
/home/hadoop/lib/sql-1.0-jar-with-dependencies.jar \
hdfs://hadoop001:8020/imooc/clean 20170511 
```



------

Boy-20180607